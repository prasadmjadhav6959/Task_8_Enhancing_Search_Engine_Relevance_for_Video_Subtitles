{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62459834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import chromadb\n",
    "# import faiss  # Alternative to chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import whisper\n",
    "from faster_whisper import WhisperModel  # Alternative to whisper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4942ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Database\n",
    "def load_data(db_path): # /content/drive/MyDrive/dataset/eng_subtitles_database.db\n",
    "    conn = sqlite3.connect(\"eng_subtitles_database.db\")\n",
    "    query = \"SELECT num, name, content FROM zipfiles;\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3114f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Subtitle Text\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, bytes):\n",
    "        text = text.decode('latin-1')  # Decode binary content\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b0bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Chunking\n",
    "def chunk_text(text, chunk_size=500, overlap=100):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff9fc17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization using TF-IDF\n",
    "def vectorize_tfidf(texts):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    return tfidf_matrix, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a564f8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization using BERT\n",
    "def vectorize_bert(texts):\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e61229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Embeddings in ChromaDB\n",
    "def store_embeddings(texts, db_name=\"chroma_subtitles\"):\n",
    "    chroma_client = chromadb.PersistentClient(path=db_name)\n",
    "    collection = chroma_client.get_or_create_collection(name=\"subtitles\")\n",
    "    for i, text in enumerate(texts):\n",
    "        collection.add(ids=[str(i)], documents=[text])\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d34587f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio to Text Conversion\n",
    "def transcribe_audio(audio_path):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(audio_path)\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "471b902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Query Execution\n",
    "def search_query(query, collection, vectorizer, tfidf_matrix, method=\"tfidf\"):\n",
    "    if method == \"tfidf\":\n",
    "        query_vec = vectorizer.transform([query])\n",
    "        similarity = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
    "    else:\n",
    "        model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "        similarity = cosine_similarity(query_embedding.cpu().numpy(), tfidf_matrix.cpu().numpy()).flatten()\n",
    "    top_indices = np.argsort(similarity)[::-1][:5]\n",
    "    return top_indices, similarity[top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40e34c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = load_data(\"eng_subtitles_database.db\")\n",
    "df[\"content\"] = df[\"content\"].apply(preprocess_text)\n",
    "df[\"chunks\"] = df[\"content\"].apply(lambda x: chunk_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "318e0e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten Chunks\n",
    "all_chunks = [chunk for sublist in df[\"chunks\"] for chunk in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02dc61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "tfidf_matrix, vectorizer = vectorize_tfidf(all_chunks)\n",
    "bert_embeddings = vectorize_bert(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in ChromaDB\n",
    "collection = store_embeddings(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3668a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setup complete. Ready for search queries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of search query\n",
    "query = \"What is the main topic?\"\n",
    "top_indices, similarities = search_query(query, collection, vectorizer, tfidf_matrix, method=\"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 5 search results (TF-IDF):\")\n",
    "for i, index in enumerate(top_indices):\n",
    "    print(f\"Result {i+1}: Similarity={similarities[i]}, Chunk: {all_chunks[index][:100]}...\") # print first 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices_bert, similarities_bert = search_query(query, collection, bert_embeddings, tfidf_matrix, method=\"bert\") # changed bert embeddings to tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18824202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop 5 search results (BERT):\")\n",
    "for i, index in enumerate(top_indices_bert):\n",
    "    print(f\"Result {i+1}: Similarity={similarities_bert[i]}, Chunk: {all_chunks[index][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71840d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More Advance Working Sonn..!\n",
    "# Notebook Project By : PRASAD JADHAV (ML-ENG)\n",
    "# LinkedIn: linkedin.com/in/prasadmjadhav2 | Github: github.com/prasadmjadhav2 | Mail: prasadmjadhav6161@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
